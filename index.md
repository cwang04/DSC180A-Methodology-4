# Methodology Assignment 4, Task 2

**Name & Email:** Colin Wang <cow004@ucsd.edu>  
**Section & Mentor:** Section A10 Alex Warstadt


**What is the most interesting topic covered in your domain this quarter?**  
The most interesting topc that was covered in our domain this quarter has been transformers. For the first couple of weeks in this capstone we went over some of the basics of natural language processing, working with some simpler topics up to the modern approaches. Learning about transformers was quite interesting since it was the first exposure I had to this topic and learning more about something that had been referenced a lot in the space of machine learning felt important.

**Describe a potential investigation you would like to pursue for your Quarter 2 Project.**  
I think pursuing a combination of modifying training methods with architectural design choices would be interesting. From the papers that we have read the two most important things from the previous BabyLM challenges was large improvements of model efficiency from architectural designs, and improving the efficency of sampling from the relatively small corpus. Something like a combination of phoneme tokenization with a model architectural improvement like the GPT-BERT model might be interesting to see if there are any improvements.

**What is a potential change you'd make to the approach taken in your current Quarter 1 Project?**  
I think the one thing I would change in approach is trying to focus on one model to work with throughout the entire quarter 1 instead of swapping around. Swapping around has made things a little tricky and a lot more work especially since the repos for them are maintained by different groups. Also I think a little bit more of a lesson on using Kubernetes would have been helpful in Quarter 1 since it was such a heavily used component of the Quarter 1 Project.

**What other techniques would you be interested in using in your project?**  
I'm not sure of what other techniques I would like to investigate in my project. I think maybe trying to utilize multiple learning techniques in the token corpus of the small data. I think the problem with using more techniques is that it beceomes harder to determine what specific change we made is an improvement or not.
